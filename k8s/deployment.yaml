apiVersion: apps/v1
kind: Deployment
metadata:
  name: llm-platform
spec:
  replicas: 1
  selector:
    matchLabels:
      app: llm-platform
  template:
    metadata:
      labels:
        app: llm-platform
    spec:
      # Init container to preload the LLM model
      initContainers:
        - name: ollama-pull-model
          image: ollama/ollama
          imagePullPolicy: IfNotPresent
          command: ["sh", "-c"]
          args:
            - |
              ollama serve & \
              sleep 5 && \
              ollama pull ${MODEL_NAME}
          envFrom:
            - configMapRef:
                name: model-config-v2
          volumeMounts:
            - name: ollama-data
              mountPath: /root/.ollama

      containers:
        # FastAPI Gateway
        - name: gateway
          image: llm-gateway:v1
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 8000
          env:
            - name: OLLAMA_URL
              value: "http://localhost:11434"
          envFrom:
            - configMapRef:
                name: model-config-v1
          readinessProbe:
            httpGet:
              path: /health
              port: 8000
            initialDelaySeconds: 10
            periodSeconds: 5
          livenessProbe:
            httpGet:
              path: /health
              port: 8000
            initialDelaySeconds: 20
            periodSeconds: 10

        # Ollama Runtime
        - name: ollama
          image: ollama/ollama
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 11434
          volumeMounts:
            - name: ollama-data
              mountPath: /root/.ollama

      volumes:
        - name: ollama-data
          emptyDir: {}



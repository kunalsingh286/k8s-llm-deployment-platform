# Kubernetes-Based LLM Deployment & Management Platform

A mini platform for deploying and managing open-source LLMs on Kubernetes
using Ollama, FastAPI, Docker, and Kubernetes.

> Phase 0: Repository initialization and project structure.

## Phase 1: Open-Source LLM Runtime Validation

- Installed Ollama runtime locally using WSL
- Pulled and ran TinyLlama (open-source LLM)
- Verified both CLI-based and HTTP API-based inference
- Confirmed feasibility of zero-cost LLM serving for platform development



